{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jyravi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jyravi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jyravi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jyravi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (1.26.19)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jyravi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\jyravi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your speech service region and the subscription_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your subscription key and region for the speech service\n",
    "SERVICE_REGION = \"\"\n",
    "\n",
    "NAME = \"Simple transcription\"\n",
    "DESCRIPTION = \"Simple transcription description\"\n",
    "\n",
    "#LOCALE = \"en-IN\"\n",
    "SUBSCRIPTION_KEY=\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<HTTPStatus.CREATED: 201>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from http import HTTPStatus\n",
    "\n",
    "expected_status_codes=[HTTPStatus.CREATED]\n",
    "expected_status_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input audio in Azure blob and defining destination url for storing the transcribed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "destcontainerurl=\"\" ### paste your Blob sas URL\n",
    "uri=f\"https://{SERVICE_REGION}.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sas_token=destcontainerurl.split(\"?\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### diarization is possible only for mono audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "content ={ \"contentUrls\": [\n",
    "    \n",
    "    \"\" # paste your url\n",
    "  ],\n",
    "  \"locale\": \"en-IN\",\n",
    "  \"displayName\": \"My Transcription\",\n",
    "  #\"model\": Null,\n",
    "\"properties\": {\n",
    "    #\"wordLevelTimestampsEnabled\": True,\n",
    "    \"diarizationEnabled\": True,\n",
    "    \"timeToLive\" : \"PT30M\",\n",
    "    \"destinationContainerUrl\":destcontainerurl,\n",
    "    \"languageIdentification\": {\n",
    "      \"candidateLocales\": [\n",
    "        \"en-IN\",\"hi-IN\"\n",
    "      ],\n",
    "    }\n",
    "  },}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'headers': {'Cache-Control': 'no-store', 'Transfer-Encoding': 'chunked', 'Content-Type': 'application/json; charset=utf-8', 'Location': 'https://eastus.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/e31b9863-c605-4023-be52-8ec8274cb48a', 'api-supported-versions': '2.0,3.0,3.1,3.2-preview2,3.2', 'api-deprecated-versions': '2.0,3.0', 'apim-request-id': '6c134555-797b-48fa-82b0-527816c3a2f1', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'Date': 'Fri, 13 Sep 2024 03:53:14 GMT'}, 'text': '{\\n  \"self\": \"https://eastus.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/e31b9863-c605-4023-be52-8ec8274cb48a\",\\n  \"links\": {\\n    \"files\": \"https://eastus.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/e31b9863-c605-4023-be52-8ec8274cb48a/files\"\\n  },\\n  \"properties\": {\\n    \"diarizationEnabled\": true,\\n    \"wordLevelTimestampsEnabled\": false,\\n    \"displayFormWordLevelTimestampsEnabled\": false,\\n    \"channels\": [\\n      0,\\n      1\\n    ],\\n    \"punctuationMode\": \"DictatedAndAutomatic\",\\n    \"profanityFilterMode\": \"Masked\",\\n    \"destinationContainerUrl\": \"https://storageacceljr.blob.core.windows.net/audiofilestranscripts?sp=racwl&st=2024-09-12T05:09:56Z&se=2024-09-30T13:09:56Z&spr=https&sv=2022-11-02&sr=c&sig=MpgLR4M5TV6hbiW9qpvgtYL%2BBmAxLKZI7yy1bfdZ%2BuE%3D\",\\n    \"timeToLive\": \"PT30M\",\\n    \"languageIdentification\": {\\n      \"mode\": \"Continuous\",\\n      \"candidateLocales\": [\\n        \"en-IN\",\\n        \"hi-IN\"\\n      ]\\n    }\\n  },\\n  \"lastActionDateTime\": \"2024-09-13T03:53:15Z\",\\n  \"status\": \"NotStarted\",\\n  \"createdDateTime\": \"2024-09-13T03:53:15Z\",\\n  \"locale\": \"en-IN\",\\n  \"displayName\": \"My Transcription\"\\n}', 'json': {'self': 'https://eastus.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/e31b9863-c605-4023-be52-8ec8274cb48a', 'links': {'files': 'https://eastus.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/e31b9863-c605-4023-be52-8ec8274cb48a/files'}, 'properties': {'diarizationEnabled': True, 'wordLevelTimestampsEnabled': False, 'displayFormWordLevelTimestampsEnabled': False, 'channels': [0, 1], 'punctuationMode': 'DictatedAndAutomatic', 'profanityFilterMode': 'Masked', 'destinationContainerUrl': 'https://storageacceljr.blob.core.windows.net/audiofilestranscripts?sp=racwl&st=2024-09-12T05:09:56Z&se=2024-09-30T13:09:56Z&spr=https&sv=2022-11-02&sr=c&sig=MpgLR4M5TV6hbiW9qpvgtYL%2BBmAxLKZI7yy1bfdZ%2BuE%3D', 'timeToLive': 'PT30M', 'languageIdentification': {'mode': 'Continuous', 'candidateLocales': ['en-IN', 'hi-IN']}}, 'lastActionDateTime': '2024-09-13T03:53:15Z', 'status': 'NotStarted', 'createdDateTime': '2024-09-13T03:53:15Z', 'locale': 'en-IN', 'displayName': 'My Transcription'}}\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Ocp-Apim-Subscription-Key\": SUBSCRIPTION_KEY}\n",
    "response = requests.post(uri, headers=headers, json=content)\n",
    "if response.status_code not in expected_status_codes :\n",
    "    raise Exception(f\"The POST request to {uri} returned a status code {response.status_code} that was not in the expected status codes: {expected_status_codes}\")\n",
    "else :\n",
    "    try :\n",
    "        response_json = response.json()\n",
    "        print({ \"headers\" : response.headers, \"text\" : response.text, \"json\" : response_json })\n",
    "    except Exception :\n",
    "        { \"headers\" : response.headers, \"text\" : response.text, \"json\" : None }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the status of the transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=requests.get(response_json['self'],headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When 'status' == 'Succeeded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json['links']['files']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the transcribed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(response_json['links']['files'],headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json=r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json['values'][0]['links']['contentUrl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results extraction when destination url is not defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we have taken the only the first ContentUrl, as we have only given one URL. This will go into a loop when you pass multiple Urls as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_wo_sas=requests.get(result_json['values'][0]['links']['contentUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.uclass.psychol.ucl.ac.uk/Release2/Conversation/AudioOnly/wav/F_0101_10y4m_1.wav',\n",
       " 'timestamp': '2024-09-12T08:46:56Z',\n",
       " 'durationInTicks': 1377811250,\n",
       " 'duration': 'PT2M17.781125S',\n",
       " 'combinedRecognizedPhrases': [{'channel': 0,\n",
       "   'lexical': \"that's enough what happened what happened after she got out out of the she found the old building where she used to live and she went inside inside it and she started to have a look around yeah what does she find in the building diesel pictures on the wall and she found this old silver line case thing you forgotten about the puppy after she was thrown out a puppy came running oh boy two men they were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother that's a great story yeah where are we\",\n",
       "   'itn': \"that's enough what happened what happened after she got out out of the she found the old building where she used to live and she went inside inside it and she started to have a look around yeah what does she find in the building diesel pictures on the wall and she found this old silver line case thing you forgotten about the puppy after she was thrown out a puppy came running oh boy two men they were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother that's a great story yeah where are we\",\n",
       "   'maskedITN': \"That's enough What happened What happened after she got out out of the She found the old building where she used to live and she went inside inside it and she started to have a look around. Yeah, what does she find in the building? Diesel pictures on the wall and she found this old Silver Line case thing You forgotten. About the puppy. After she was thrown out, a puppy came running. Oh boy two men They were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother That's a great story Yeah. Where are we?\",\n",
       "   'display': \"That's enough. What happened? What happened after she got out out of the? She found the old building where she used to live and she went inside inside it and she started to have a look around. Yeah, what does she find in the building? Diesel pictures on the wall and she found this old Silver Line case thing You forgotten. About the puppy. After she was thrown out, a puppy came running. Oh boy, two men. They were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother. That's a great story. Yeah. Where are we?\"}],\n",
       " 'recognizedPhrases': [{'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT0.48S',\n",
       "   'duration': 'PT0.6S',\n",
       "   'offsetInTicks': 4800000.0,\n",
       "   'durationInTicks': 6000000.0,\n",
       "   'nBest': [{'confidence': 0.6899235,\n",
       "     'lexical': \"that's enough\",\n",
       "     'itn': \"that's enough\",\n",
       "     'maskedITN': \"That's enough\",\n",
       "     'display': \"That's enough.\"}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT1.72S',\n",
       "   'duration': 'PT0.6S',\n",
       "   'offsetInTicks': 17200000.0,\n",
       "   'durationInTicks': 6000000.0,\n",
       "   'nBest': [{'confidence': 0.77839774,\n",
       "     'lexical': 'what happened',\n",
       "     'itn': 'what happened',\n",
       "     'maskedITN': 'What happened',\n",
       "     'display': 'What happened?'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT2.32S',\n",
       "   'duration': 'PT2.32S',\n",
       "   'offsetInTicks': 23200000.0,\n",
       "   'durationInTicks': 23200000.0,\n",
       "   'nBest': [{'confidence': 0.744316,\n",
       "     'lexical': 'what happened after she got out out of the',\n",
       "     'itn': 'what happened after she got out out of the',\n",
       "     'maskedITN': 'What happened after she got out out of the',\n",
       "     'display': 'What happened after she got out out of the?'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 2,\n",
       "   'offset': 'PT8.08S',\n",
       "   'duration': 'PT20.44S',\n",
       "   'offsetInTicks': 80800000.0,\n",
       "   'durationInTicks': 204400000.0,\n",
       "   'nBest': [{'confidence': 0.82946783,\n",
       "     'lexical': 'she found the old building where she used to live and she went inside inside it and she started to have a look around',\n",
       "     'itn': 'she found the old building where she used to live and she went inside inside it and she started to have a look around',\n",
       "     'maskedITN': 'She found the old building where she used to live and she went inside inside it and she started to have a look around.',\n",
       "     'display': 'She found the old building where she used to live and she went inside inside it and she started to have a look around.'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT40.88S',\n",
       "   'duration': 'PT1.76S',\n",
       "   'offsetInTicks': 408800000.0,\n",
       "   'durationInTicks': 17600000.0,\n",
       "   'nBest': [{'confidence': 0.72536635,\n",
       "     'lexical': 'yeah what does she find in the building',\n",
       "     'itn': 'yeah what does she find in the building',\n",
       "     'maskedITN': 'Yeah, what does she find in the building?',\n",
       "     'display': 'Yeah, what does she find in the building?'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 2,\n",
       "   'offset': 'PT48.84S',\n",
       "   'duration': 'PT15.96S',\n",
       "   'offsetInTicks': 488400000.0,\n",
       "   'durationInTicks': 159600000.0,\n",
       "   'nBest': [{'confidence': 0.50554794,\n",
       "     'lexical': 'diesel pictures on the wall and she found this old silver line case thing you forgotten',\n",
       "     'itn': 'diesel pictures on the wall and she found this old silver line case thing you forgotten',\n",
       "     'maskedITN': 'Diesel pictures on the wall and she found this old Silver Line case thing You forgotten.',\n",
       "     'display': 'Diesel pictures on the wall and she found this old Silver Line case thing You forgotten.'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT1M14.37S',\n",
       "   'duration': 'PT1.12S',\n",
       "   'offsetInTicks': 743700000.0,\n",
       "   'durationInTicks': 11200000.0,\n",
       "   'nBest': [{'confidence': 0.6170503,\n",
       "     'lexical': 'about the puppy',\n",
       "     'itn': 'about the puppy',\n",
       "     'maskedITN': 'About the puppy.',\n",
       "     'display': 'About the puppy.'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 2,\n",
       "   'offset': 'PT1M22.32S',\n",
       "   'duration': 'PT5.12S',\n",
       "   'offsetInTicks': 823200000.0,\n",
       "   'durationInTicks': 51200000.0,\n",
       "   'nBest': [{'confidence': 0.7706345,\n",
       "     'lexical': 'after she was thrown out a puppy came running',\n",
       "     'itn': 'after she was thrown out a puppy came running',\n",
       "     'maskedITN': 'After she was thrown out, a puppy came running.',\n",
       "     'display': 'After she was thrown out, a puppy came running.'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 2,\n",
       "   'offset': 'PT1M39.64S',\n",
       "   'duration': 'PT3.2S',\n",
       "   'offsetInTicks': 996400000.0,\n",
       "   'durationInTicks': 32000000.0,\n",
       "   'nBest': [{'confidence': 0.2573978,\n",
       "     'lexical': 'oh boy two men',\n",
       "     'itn': 'oh boy two men',\n",
       "     'maskedITN': 'Oh boy two men',\n",
       "     'display': 'Oh boy, two men.'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT2M0.44S',\n",
       "   'duration': 'PT10.4S',\n",
       "   'offsetInTicks': 1204400000.0,\n",
       "   'durationInTicks': 104000000.0,\n",
       "   'nBest': [{'confidence': 0.67551905,\n",
       "     'lexical': 'they were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother',\n",
       "     'itn': 'they were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother',\n",
       "     'maskedITN': 'They were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother',\n",
       "     'display': 'They were trying to find what they were trying to sort of audition and they people to pretend to be her so they can get the money from the grandmother.'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT2M10.84S',\n",
       "   'duration': 'PT3.36S',\n",
       "   'offsetInTicks': 1308400000.0,\n",
       "   'durationInTicks': 33600000.0,\n",
       "   'nBest': [{'confidence': 0.44927013,\n",
       "     'lexical': \"that's a great story\",\n",
       "     'itn': \"that's a great story\",\n",
       "     'maskedITN': \"That's a great story\",\n",
       "     'display': \"That's a great story.\"}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 2,\n",
       "   'offset': 'PT2M14.44S',\n",
       "   'duration': 'PT0.24S',\n",
       "   'offsetInTicks': 1344400000.0,\n",
       "   'durationInTicks': 2400000.0,\n",
       "   'nBest': [{'confidence': 0.25576857,\n",
       "     'lexical': 'yeah',\n",
       "     'itn': 'yeah',\n",
       "     'maskedITN': 'Yeah.',\n",
       "     'display': 'Yeah.'}],\n",
       "   'locale': 'en-US'},\n",
       "  {'recognitionStatus': 'Success',\n",
       "   'channel': 0,\n",
       "   'speaker': 1,\n",
       "   'offset': 'PT2M16.52S',\n",
       "   'duration': 'PT0.6S',\n",
       "   'offsetInTicks': 1365200000.0,\n",
       "   'durationInTicks': 6000000.0,\n",
       "   'nBest': [{'confidence': 0.8601625,\n",
       "     'lexical': 'where are we',\n",
       "     'itn': 'where are we',\n",
       "     'maskedITN': 'Where are we?',\n",
       "     'display': 'Where are we?'}],\n",
       "   'locale': 'en-US'}]}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_wo_sas.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sas_token for the destination_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sas_token= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### constructing the url with sas_token for reading the file from destination url\n",
    "##### Please create loop for reading through all the contentUrls if a list of URLs are provided for transcribing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri=result_json['values'][0]['links']['contentUrl']+\"?\"+Sas_token\n",
    "file_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=requests.get(url=file_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'timestamp', 'durationInTicks', 'duration', 'combinedRecognizedPhrases', 'recognizedPhrases'])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.json().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below step is one way to combine the speaker and the utterance. There could be other ways,please feel free to make those according how the the use wants the output to look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=[]\n",
    "for i in result.json()['recognizedPhrases']:\n",
    "    if i[\"recognitionStatus\"]=='Success':\n",
    "        #print('speaker '+ str(i['speaker'])+\":\")\n",
    "        #print(i['nBest'][0]['lexical'])\n",
    "        conversation.append(['speaker '+ str(i['speaker'])+\": \"+ i['nBest'][0]['lexical']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['speaker 1: good evening'],\n",
       " ['speaker 1: welcome to bhroove'],\n",
       " ['speaker 1: how can i help you'],\n",
       " ['speaker 2: sir sir'],\n",
       " ['speaker 2: बोल रहा हूँ'],\n",
       " ['speaker 1: हैलो हाँ सर बताइए क्या जानना है आपको'],\n",
       " ['speaker 2: मैने'],\n",
       " ['speaker 2: अभी मैं शाम में अपना अकाउन्ट बैलेंस देखा था तो सोलह सोलह सौ चौंसठ रुपए था बट अभी सिक्सटीन हंड्रेड फॉर्टी नाइन दिखा रहा'],\n",
       " ['speaker 1: है'],\n",
       " ['speaker 2: तो पंद्रह रुपए का काट'],\n",
       " ['speaker 2: thank you sir bataaenge'],\n",
       " ['speaker 1: check karo akhilesh pratap singh ka naam se'],\n",
       " ['speaker 1: रात को होती है चार्जेज वगैरह रात को डिडक्ट होते है अपने यहाँ पे'],\n",
       " ['speaker 1: h d f c sell kara ek aur h f sale yahaan pe trade kara to yahaan pe deposit'],\n",
       " ['speaker 1: आपको वॅन फाइव पॉइंट नाइन का रहेगा डी पी चार्जेज लगाया'],\n",
       " ['speaker 2: अच्छा'],\n",
       " ['speaker 1: तो'],\n",
       " ['speaker 2: एक रुपए डिडक्ट करना चाहिए ना तो कितना पंद्रह रुपए'],\n",
       " ['speaker 1: एक रुपए के होगा सर वॅन फाइव पॉइंट नाइन थ्री ये डेपॉज़िट चार्जेज पर कंपनी का ये आपको सी डी एस एल चार्ज करती है फिफ्टीन रूपीस नाइनटीन थ्री पर कंपनी'],\n",
       " ['speaker 2: पेमेंट हो जाता है आप लोग बाद में चार्जेज डिडक्ट करते'],\n",
       " ['speaker 1: हो रात को सेट्लमेंट होती है आज से दस बजे के बीच में सब जो भी चार्जेज रहते है डेट ऑफ़ रूपीस'],\n",
       " ['speaker 2: ओके ठीक है ठीक है'],\n",
       " ['speaker 2: एक मिनट सर थैंक यू'],\n",
       " ['speaker 1: थैंक यू सो मच सर कॉल ट्रांसफर होगा']]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing \"conversation\" dynamically to AOAI.\n",
    "\n",
    "##### Please make necessary changes in the system prompt to suit your use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# Configuration\n",
    "API_KEY = \"\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": API_KEY,\n",
    "}\n",
    "\n",
    "# Payload for the request\n",
    "payload = { \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": '''You are AI assistant for analyzing transcripts between customer support agent and the customer. \n",
    "          You will be provided with the conversation transcripts with speakers diarized as speaker 1 and speaker 2.\n",
    "          1. Identify agent and customer from the conversation flow.\n",
    "          2.  Summarize the issue/query/concern from the customer?\n",
    "          3. Summarize the response provided by the agent.\n",
    "          4. Was the customer satisfied with the resolution provided by the agent?\n",
    "          5.Overall sentiment at the end of the call.\n",
    "          Please respond with the answers in the below json format\n",
    "          \"{\"Speaker 1\": \"\",\n",
    "          \"Speaker 2\": \" \",\n",
    "          \"Issue\" : \" \",\n",
    "          \"Resolution\":\"\",\n",
    "          \"Customer Satified\" : \" \",\n",
    "          \"Overall Sentiment\": \" \"}\"'''\n",
    "          \n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": f\"{conversation}\"\n",
    "        }\n",
    "      ]\n",
    "    },],  \n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800}\n",
    "\n",
    "ENDPOINT = f\"https://{}.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': '```json\\n{\\n  \"Speaker 1\": \"Agent\",\\n  \"Speaker 2\": \"Customer\",\\n  \"Issue\": \"The customer observed a deduction of Rs 15 from his account balance and wanted to understand the reason for this deduction.\",\\n  \"Resolution\": \"The agent explained that the deduction was due to DP (Depository Participant) charges that are applied during the night settlement process. Specifically, a charge of Rs 15.93 was deducted as part of the company\\'s CDS (Central Depository Services) charges.\",\\n  \"Customer Satisfied\": \"Yes\",\\n  \"Overall Sentiment\": \"Neutral to Positive\"\\n}\\n```', 'role': 'assistant'}}], 'created': 1726200458, 'id': 'chatcmpl-A6rsoJEckj8sH70LGMGCFywI1bCrk', 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'system_fingerprint': 'fp_80a1bad4c7', 'usage': {'completion_tokens': 128, 'prompt_tokens': 629, 'total_tokens': 757}}\n"
     ]
    }
   ],
   "source": [
    "# Send request\n",
    "try:\n",
    "    response = requests.post(ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response as needed (e.g., print or process)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Speaker 1\": \"Agent\",\n",
      "  \"Speaker 2\": \"Customer\",\n",
      "  \"Issue\": \"The customer observed a deduction of Rs 15 from his account balance and wanted to understand the reason for this deduction.\",\n",
      "  \"Resolution\": \"The agent explained that the deduction was due to DP (Depository Participant) charges that are applied during the night settlement process. Specifically, a charge of Rs 15.93 was deducted as part of the company's CDS (Central Depository Services) charges.\",\n",
      "  \"Customer Satisfied\": \"Yes\",\n",
      "  \"Overall Sentiment\": \"Neutral to Positive\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
